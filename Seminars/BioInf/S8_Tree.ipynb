{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Existanze54/sirius-machine-learning-2025/blob/main/Seminars/BioInf/S8_Tree.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NrdaY2Q1x_A"
      },
      "source": [
        "# Основные методы ML\n",
        "\n",
        "### Семинар 8: Деревья решений и случайный лес\n",
        "\n",
        "Максимальная глубина, связь с variance. Bagging деревьев. One-hot кодирование. Оптимизация параметров GridSearchCV"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCxnBz_L1LSD"
      },
      "source": [
        "import scipy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "from sklearn.model_selection import KFold, GridSearchCV, train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIoYd7az2Jsy"
      },
      "source": [
        "### Задача 1: Bias-variance trade-off\n",
        "\n",
        "\n",
        "Продемонстрируйте bias-variance trade-off на примере DecisionTreeRegressor на представленном датасете, используя функцию plot_regression_predictions и приведенный ниже код (можете модифицировать).\n",
        "\n",
        "*Подсказка*: попробуйте несколько значений глубины *max_depth* в пределах от 2 до 12 и сравните с дефолтным None. Также можете попробовать варьировать другие параметры."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubA-dRmW1yFp"
      },
      "source": [
        "np.random.seed(42)\n",
        "m = 200\n",
        "X = np.random.rand(m, 1) * 3 - 1\n",
        "y = 4 * (X - 0.5) ** 3\n",
        "y = y + np.random.randn(m, 1) / 10\n",
        "\n",
        "# визуализируем\n",
        "plt.scatter(X,y,s=10)\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z-OTg4Er1yHy"
      },
      "source": [
        "def plot_regression_predictions(tree_reg, X, y, ax, limits=[0, 1, -1, 1], title=\"\"):\n",
        "    \"\"\"Передайте обученное дерево, координаты кривой Х и y,\n",
        "        объект ax для отрисовки, опционально - координаты границ\n",
        "         и заголовок графика\"\"\"\n",
        "    x1 = np.linspace(limits[0], limits[1], 500).reshape(-1, 1)\n",
        "    y_pred = tree_reg.predict(x1)\n",
        "    ax.axis(limits)\n",
        "    ax.set_title(title)\n",
        "    ax.plot(X, y, \"b.\")\n",
        "    ax.plot(x1, y_pred, \"r.-\", alpha=0.1, linewidth=1, label=\"y\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4WmPs-nTFEo"
      },
      "source": [
        "# Замените \"?\" рабочим кодом либо напишите полностью свое решение\n",
        "fig, axes = plt.subplots(2,3, figsize=(12,15))\n",
        "axes = axes.flat\n",
        "\n",
        "for i, d in enumerate( ?? ):\n",
        "    axes[i].set(xlabel=\"$x_1$\", ylabel=\"$y$\")\n",
        "    axes[i].label_outer()\n",
        "    model = DecisionTreeRegressor(max_depth=??).fit(??, ?)\n",
        "    plot_regression_predictions(???, ??, ?, axes[i], limits=[0, 1, -1, 1], title=f\"Max depth: {d}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehQAquBPMKhv"
      },
      "source": [
        "# Выводы - ?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PWjntNx1gnl"
      },
      "source": [
        "### Задача 2: Качество Bagging с различными базовыми моделями\n",
        "\n",
        "Попробуем оценить эффект бэггинга на качестве различных моделей классификации: логистической регрессии, SVC и дерева решений.\n",
        "\n",
        "На датасете *breast_cancer* обучите модели Decision Tree, SVC (с параметрами по умолчанию) и логистическую регрессию.\n",
        "\n",
        "Полученные предсказания на тесте оцените при помощи корреляции мэтьюса (**sklearn.metrics.matthews_corrcoef**, почитать про пользу этой метрики можно [здесь](https://bmcgenomics.biomedcentral.com/articles/10.1186/s12864-019-6413-7)), построив 90% доверительные интервалы при помощи реализующей bootstrap функции *bootstrap_metric*. Результат отобразите в виде боксплотов.\n",
        "\n",
        "Обучите **BaggingClassifier** (предварительно почитав [документацию](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html)) с теми же самыми моделями в качестве базового эстиматора и числом эстиматоров равным 100.\n",
        "\n",
        "На новом графике отобразите боксплоты для всех 6 моделей. Сделайте выводы."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hVRK_B3Faeg5"
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "def bootstrap_metric(x, y,\n",
        "                    metric_fn,\n",
        "                    samples_cnt=1000,\n",
        "                    random_state=777):\n",
        "    size = len(x)\n",
        "    np.random.seed(random_state)\n",
        "    b_metric = np.zeros(samples_cnt)\n",
        "    for it in range(samples_cnt):\n",
        "        poses = np.random.choice(x.shape[0], size=x.shape[0], replace=True)\n",
        "\n",
        "        x_boot = x[poses]\n",
        "        y_boot = y[poses]\n",
        "\n",
        "        m_val = metric_fn(x_boot, y_boot)\n",
        "        b_metric[it] = m_val\n",
        "\n",
        "    return b_metric"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gTSg26thaejS"
      },
      "source": [
        "breast_cancer = load_breast_cancer()\n",
        "#print(breast_cancer.DESCR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufhspv5baelQ"
      },
      "source": [
        "X = breast_cancer.data\n",
        "y = breast_cancer.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=777)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBEU8nZT5QiZ"
      },
      "source": [
        "Обучите базовые модели и сравните качество:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZWZ4hKZfSS8"
      },
      "source": [
        "logr_model = LogisticRegression(solver='liblinear',\\\n",
        "                                max_iter=1000).fit(X_train, y_train)\n",
        "\n",
        "dt_model = DecisionTreeClassifier().fit(??)\n",
        "\n",
        "svc_model = SVC().fit(??)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hs-5uFx3aepZ"
      },
      "source": [
        "dt_pred    =   dt_model.predict(X_test)\n",
        "svc_pred   =   # your code here\n",
        "logr_pred  =   # your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUHR-faaaerU"
      },
      "source": [
        "boot_score_dt = bootstrap_metric(y_test,\n",
        "                                   dt_pred,\n",
        "                                   metric_fn=lambda x, y: matthews_corrcoef(y_true=x,\n",
        "                                                                                  y_pred=y))\n",
        "boot_score_svc = bootstrap_metric(y_test,\n",
        "                                   svc_pred,\n",
        "                                   metric_fn=lambda x, y: matthews_corrcoef(y_true=x,\n",
        "                                                                                  y_pred=y))\n",
        "boot_score_logr = bootstrap_metric(y_test,\n",
        "                                   logr_pred,\n",
        "                                   metric_fn=lambda x, y: matthews_corrcoef(y_true=x,\n",
        "                                                                                  y_pred=y))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pcj7OPMJaetr"
      },
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "sns.boxplot(y=np.concatenate([boot_score_dt,\n",
        "                              boot_score_svc,\n",
        "                              boot_score_logr]),\n",
        "             x=[\"DT\"] * 1000 + ['SVC'] * 1000 + ['Log-reg'] * 1000 )\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_FGqp415VL_"
      },
      "source": [
        "Создайте ансамбли BaggingClassifier с рассмотренными выше моделями в качестве базовых эстиматоров и числом эстиматоров равным 100. Получите для каждого из них предсказание и bootstrap-оценку. Добавьте полученные данные на график."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-AIfcMdfBBb"
      },
      "source": [
        "bagged_svc_model = BaggingClassifier(SVC(), \\\n",
        "                                     n_estimators=100).fit(X_train, y_train)\n",
        "# your code here\n",
        "# your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIUJrv_aaex3"
      },
      "source": [
        "b_dt_pred    =  bagged_dt_model.predict(X_test)\n",
        "# your code here\n",
        "# your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GrlrjLqVae0I"
      },
      "source": [
        "matthews_m = lambda x, y: matthews_corrcoef(y_true=x, y_pred=y)\n",
        "\n",
        "# your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKFwU2exae1o"
      },
      "source": [
        "plt.figure(figsize=(12,8))\n",
        "sns.boxplot(y=np.concatenate([boot_score_dt,\n",
        "                              b_boot_score_dt,\n",
        "                              boot_score_svc,\n",
        "                              b_boot_score_svc,\n",
        "                              boot_score_logr,\n",
        "                              b_boot_score_logr]),\n",
        "             x=[\"DT\"] * 1000 + [\"Bagged DT\"] * 1000 + ['SVC'] * 1000 \\\n",
        "             + ['Bagged SVC'] * 1000 + ['Log-reg'] * 1000 + ['Bagged Log-reg'] * 1000)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKZEvwJE6iDO"
      },
      "source": [
        "# Вывод -?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejmQcq7r3X0k"
      },
      "source": [
        "### Задача 3: Древесные модели и работа с признаками.\n",
        "\n",
        "Поработаем с  [датасетом](https://www.kaggle.com/ronitf/heart-disease-uci), содержащим признаковые описания здоровых людей и пациентов с заболеваниями сердца."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://data.bioml.ru/htdocs/courses/python/datasci/pandas/data/heart_uci_cleveland.csv -O heart.csv"
      ],
      "metadata": {
        "id": "5vGyFQHj5QDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60VAu8yY5ybh"
      },
      "source": [
        "heart_dataset = pd.read_csv(\"heart.csv\")\n",
        "print(heart_dataset.shape)\n",
        "print(heart_dataset.columns.values)\n",
        "X = heart_dataset.drop(\"condition\", axis=1)\n",
        "y = heart_dataset['condition'] > 0\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y.values, random_state=777)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afz-AF335ybh"
      },
      "source": [
        "heart_dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQ2OOjxbV62j"
      },
      "source": [
        "#### Эксперимент: обучение классификаторов на вещественных признаках"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRA2NflRT0Au"
      },
      "source": [
        "Качество алгоритмов может зависеть не только от значений гиперпараметров, но и от предобратки исходных признаков. Некоторые из рассмотренных нами алгоритмов чувствительны к масштабу признаков. Посмотрим, насколько различны распределения признаков. Постройте гистограммы для признаков 'age', 'trestbps', 'chol', 'thalach', 'oldpeak'.\n",
        "\n",
        "Глядя на получившиеся графики, скажите в чем заключается особенность данных? На какие алгоритмы это может повлиять? Почему?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iificxxT8Tt"
      },
      "source": [
        "fig, axes = plt.subplots(3,2, figsize=(12,10))\n",
        "axes = axes.flat\n",
        "for i, name in enumerate( ??? ):\n",
        "    heart_dataset[name].hist(ax=axes[i])\n",
        "    axes[i].set_title(name)\n",
        "fig.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBBSs1ydT7t_"
      },
      "source": [
        "Масштабирование признаков можно выполнить, например, одним из следующих способов:\n",
        "\n",
        "$x_{new} = \\dfrac{x - \\mu}{\\sigma}$, где $\\mu, \\sigma$ — среднее и стандартное отклонение значения признака по всей выборке;\n",
        "\n",
        "$x_{new} = \\dfrac{x - x_{min}}{x_{max} - x_{min}}$, где $[x_{min}, x_{max}]$ —  интервал наблюдаемых значений признака.\n",
        "\n",
        "Такие схемы масштабирования приведены в классах [StandardScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html#sklearn.preprocessing.StandardScaler) и [MinMaxScaler](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MinMaxScaler.html#sklearn.preprocessing.MinMaxScaler).\n",
        "\n",
        "Отберите все вещественные признаки и масштабируйте их одним из указанных способов.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gl03W2O8T76X"
      },
      "source": [
        "from sklearn.preprocessing import ??Scaler\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OspIFIZeHVHa"
      },
      "source": [
        "В этой задаче будем рассматривать алгоритм *RandomForestClassifier*.\n",
        "\n",
        "Для начала оцените среднее и std качества работы алгоритма с параметрами по умолчанию на масштабированных и исходных вещественных признаках из тренировочной выборки при помощи функции [cross_val_score](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_val_score.html). По умолчанию она оценивает качество работы модели по 5 фолдам.\n",
        "\n",
        "\n",
        "Сделайте вывод о необходимости масштабировать признаки перед подачей их в древесные модели."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeefBXTF0GEm"
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "cross_val_score(estimator=RandomForestClassifier(), X=??, y=??)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xukes39I0vEq"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T48uDusFR7v6"
      },
      "source": [
        "# Вывод"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5WmI0X2DVWV"
      },
      "source": [
        "#### Добавление категориальных признаков в модель\n",
        "\n",
        "Вспомним, что у нас еще есть категориальные признаки. Случайный лес умеет работать с ними напрямую в том виде, в котором они в датасете находятся сейчас, однако многие другие модели требуют дополнительной предобработки.\n",
        "\n",
        "Преобразуйте все категориальные признаки с помощью метода one-hot-encoding (например, это можно сделать с помощью функции [pandas.get_dummies](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html)). Передайте в функцию список колонок, которые необходимо закодировать.\n",
        "\n",
        "После кодирования признаков разбейте датасет заново на тренировочную и тестовую выборки тем же способом, что и раньше."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USqvKoP-DVdn"
      },
      "source": [
        "heart_dataset_transformed = pd.get_dummies(heart_dataset, columns = [ ??? ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHt1Wygq0GK5"
      },
      "source": [
        "Обучим случайный лес.\n",
        "\n",
        "Подберите для него оптимальные значения гиперпараметров, а именно параметр глубины (*max_depth*), критерий разбиения в деревьях (*criterion*) и максимальное число признаков *max_features*.\n",
        "\n",
        "Для подбора гиперпараметров воспользуйтесь перебором по сетке, который реализован в классе [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html). Для ускорения вычислений можете передать параметр *n_jobs = -1*.\n",
        "\n",
        "Обратите внимание, что эта операция может быть ресурсо- и трудоемкой! Не используйте большие массивы перебираемых значений параметров."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "NlVek7FY-AgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mk6FN4n2AK6G"
      },
      "source": [
        "params = {\n",
        "    \"n_estimators\": [1, 10, 100],\n",
        "    \"max_depth\": [2, 5, 7, 10, 15, None],\n",
        "    \"criterion\": [\"gini\", \"entropy\"],\n",
        "    \"max_features\": [\"sqrt\", \"log2\", None]\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(???, params, verbose=3, n_jobs=-1)\n",
        "grid.fit(??, ?)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h58HH5-x2nOt"
      },
      "source": [
        "Оцените качество предсказания обученной на всех признаках модели на тесте. Используйте classification_report."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2btuaxVAHVT1"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KBDSqgN893q"
      },
      "source": [
        "# Выводы"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}